{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c7e85e",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1150ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac8a9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71644a33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9487fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        207\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "ocean_proximity         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chack missing value in the dataset\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2e333",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e49996",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill missing value with 0\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f89eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new features\n",
    "df['rooms_per_household'] = df['total_rooms']/df['households']\n",
    "df['bedrooms_per_room'] = df['total_bedrooms']/df['total_rooms']\n",
    "df['population_per_household'] = df['population']/df['households']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ccfe51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "      <th>rooms_per_household</th>\n",
       "      <th>bedrooms_per_room</th>\n",
       "      <th>population_per_household</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>2.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.155797</td>\n",
       "      <td>2.109842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>0.129516</td>\n",
       "      <td>2.802260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>0.184458</td>\n",
       "      <td>2.547945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>0.172096</td>\n",
       "      <td>2.181467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \\\n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY   \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY   \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY   \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY   \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY   \n",
       "\n",
       "   rooms_per_household  bedrooms_per_room  population_per_household  \n",
       "0             6.984127           0.146591                  2.555556  \n",
       "1             6.238137           0.155797                  2.109842  \n",
       "2             8.288136           0.129516                  2.802260  \n",
       "3             5.817352           0.184458                  2.547945  \n",
       "4             6.281853           0.172096                  2.181467  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afb7c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the data if the data will use for other method \n",
    "df_reg = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4645f4",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "What is the most frequent observation (mode) for the column ocean_proximity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b636481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<1H OCEAN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "mode = statistics.mode(df['ocean_proximity'])\n",
    "mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc3618c",
   "metadata": {},
   "source": [
    "the most frequent value from ocean_proximity column is '<1H OCEAN'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a4aca",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "- Create the correlation matrix for the numerical features of your train dataset.\n",
    "- In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "- What are the two features that have the biggest correlation in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f9cee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate both numerical columns and categorical columns\n",
    "\n",
    "numerical = ['latitude',\n",
    "'longitude',\n",
    "'housing_median_age',\n",
    "'total_rooms',\n",
    "'total_bedrooms',\n",
    "'population',\n",
    "'households',\n",
    "'median_income',\n",
    "'median_house_value',\n",
    "'rooms_per_household',\n",
    "'bedrooms_per_room',\n",
    "'population_per_household']\n",
    "\n",
    "categorical=['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f11c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chack correlation between 2 variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f52bde4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                   -0.071035\n",
       "longitude                   0.055310\n",
       "housing_median_age         -0.302916\n",
       "total_rooms                 0.918484\n",
       "total_bedrooms              0.966507\n",
       "population                  0.907222\n",
       "households                  1.000000\n",
       "median_income               0.013033\n",
       "median_house_value          0.065843\n",
       "rooms_per_household        -0.080598\n",
       "bedrooms_per_room           0.059818\n",
       "population_per_household   -0.027309\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical].corrwith(df['households'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad59244f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude                   -0.036100\n",
       "longitude                   0.044568\n",
       "housing_median_age         -0.361262\n",
       "total_rooms                 1.000000\n",
       "total_bedrooms              0.920196\n",
       "population                  0.857126\n",
       "households                  0.918484\n",
       "median_income               0.198050\n",
       "median_house_value          0.134153\n",
       "rooms_per_household         0.133798\n",
       "bedrooms_per_room          -0.174583\n",
       "population_per_household   -0.024581\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical].corrwith(df['total_rooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d1d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "the two features that have the biggest correlation in this dataset is total_bedrooms and households with value by 0.966507 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83f75c3",
   "metadata": {},
   "source": [
    "Make median_house_value binary\n",
    "We need to turn the median_house_value variable from numeric into binary.\n",
    "Let's create a variable above_average which is 1 if the median_house_value is above its mean value and 0 otherwise.\n",
    "Split the data\n",
    "Split your data in train/val/test sets, with 60%/20%/20% distribution.\n",
    "Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "Make sure that the target value (median_house_value) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26b2352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = []\n",
    "above_average=statistics.mean(df['median_house_value'])\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if df['median_house_value'][i] > above_average:\n",
    "        uu.append(1)\n",
    "    else:\n",
    "        uu.append(0)\n",
    "        \n",
    "df['median_house_value'] = uu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "077f66a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215b9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c4eaf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.median_house_value.values\n",
    "y_val = df_val.median_house_value.values\n",
    "y_test = df_test.median_house_value.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bdd04083",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_train['median_house_value']\n",
    "del df_val['median_house_value']\n",
    "del df_test['median_house_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cbd67d",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "- Calculate the mutual information score with the (binarized) price for the categorical variable that we have. Use the training set only.\n",
    "- What is the value of mutual information?\n",
    "- Round it to 2 decimal digits using round(score, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a976fc9b",
   "metadata": {},
   "source": [
    "Mutual information is a concept from information theory, which measures how much we can \n",
    "learn about one variable if we know the value of another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb4a8819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "def mutual_info_house_value_score(x):\n",
    "    return round(mutual_info_score(x, y_train),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a54fef2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ocean_proximity    0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[categorical].apply(mutual_info_house_value_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad3ddf9",
   "metadata": {},
   "source": [
    "mutual informatin score based on the dataset approximately 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daae82e5",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "- Now let's train a logistic regression\n",
    "- Remember that we have one categorical variable ocean_proximity in the data. Include it using one-hot encoding.\n",
    "- Fit the model on the training dataset.\n",
    "- To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "- model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "- Calculate the accuracy on the validation dataset and round it to 2 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7606fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneHotEncoding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "df_train['ocean_proximity'] = ohe.fit_transform(df_train[categorical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa2ee919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96feb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding categorical value in the validation dataset\n",
    "df_val['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8a33130",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_proba(df_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34d208d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = round(accuracy_score(y_val, y_pred>= 0.5),2)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5511f86",
   "metadata": {},
   "source": [
    "Accuracy based on my model = 0.82\n",
    "Because my answer can't appear in the option, i choose for accuracy on the validation dataset with model that get  approximately 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced5aad",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "- Let's find the least useful feature using the feature elimination technique.\n",
    "- Train a model with all these features (using the same parameters as in Q4).\n",
    "- Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "- For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "- Which of following feature has the smallest difference?\n",
    "\n",
    "options:\n",
    "- total_rooms\n",
    "- total_bedrooms\n",
    "- population\n",
    "- households"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aab1b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 5\n",
    "\n",
    "def diff_accuracy(G,i):\n",
    "    #col = ['total_rooms','total_bedrooms','population','households']\n",
    "    df_full_train, df_test = train_test_split(G, test_size=0.2, random_state=42)\n",
    "    df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "    \n",
    "    X=df_train\n",
    "    Y=df_val\n",
    "    Z=df_test\n",
    "    \n",
    "    y_train = X.median_house_value.values\n",
    "    y_val = Y.median_house_value.values\n",
    "    y_test = Z.median_house_value.values\n",
    "    \n",
    "    del X['median_house_value']\n",
    "    del Y['median_house_value']\n",
    "    del Z['median_house_value']\n",
    "    \n",
    "    X=X.loc[:, X.columns != i ]\n",
    "    Y=Y.loc[:, Y.columns != i ]\n",
    "    Z=Z.loc[:, Z.columns != i ]\n",
    "    \n",
    "    categorical=['ocean_proximity']\n",
    "    \n",
    "    X['ocean_proximity'] = ohe.fit_transform(X[categorical].values)\n",
    "    Y['ocean_proximity'] = ohe.fit_transform(Y[categorical].values)\n",
    "    Z['ocean_proximity'] = ohe.fit_transform(Z[categorical].values)\n",
    "        \n",
    "    model = LogisticRegression(solver=\"liblinear\", C=1.0, max_iter=1000, random_state=42)\n",
    "    model.fit(X, y_train)\n",
    "\n",
    "    Y['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)\n",
    "    y_pred = model.predict_proba(Y)[:, 1]\n",
    "    accu = accuracy_score(y_val, y_pred>= 0.5)\n",
    "\n",
    "    return accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d33ea33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-060f4f971e2b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ocean_proximity'] = ohe.fit_transform(X[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(Y[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Z['ocean_proximity'] = ohe.fit_transform(Z[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ocean_proximity'] = ohe.fit_transform(X[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(Y[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Z['ocean_proximity'] = ohe.fit_transform(Z[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ocean_proximity'] = ohe.fit_transform(X[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(Y[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Z['ocean_proximity'] = ohe.fit_transform(Z[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['ocean_proximity'] = ohe.fit_transform(X[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(Y[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Z['ocean_proximity'] = ohe.fit_transform(Z[categorical].values)\n",
      "<ipython-input-26-060f4f971e2b>:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Y['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "col = ['total_rooms','total_bedrooms','population','households']\n",
    "for i in col: \n",
    "    score.append(diff_accuracy(df, str(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6034a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_accuracy_without_total_rooms = accuracy - score[0]\n",
    "diff_accuracy_without_total_bedrooms = accuracy - score[1]\n",
    "diff_accuracy_without_population = accuracy - score[2]\n",
    "diff_accuracy_without_households = accuracy - score[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9e9ca1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff_accuracy_without_total_rooms = -0.003643410852713247\n",
      "diff_accuracy_without_total_bedrooms = -0.002189922480620221\n",
      "diff_accuracy_without_population = -0.0029166666666666785\n",
      "diff_accuracy_without_households = -0.003643410852713247\n"
     ]
    }
   ],
   "source": [
    "print('diff_accuracy_without_total_rooms =',diff_accuracy_without_total_rooms)\n",
    "print('diff_accuracy_without_total_bedrooms =',diff_accuracy_without_total_bedrooms)\n",
    "print('diff_accuracy_without_population =',diff_accuracy_without_population)\n",
    "print('diff_accuracy_without_households =',diff_accuracy_without_households)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991b21a4",
   "metadata": {},
   "source": [
    "As you can see, for all difference value is negative. Based on the results, we can prove that the calculation is right\n",
    "So,the smallest difference based on above: if we don't use total rooms column or households column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a7fa65",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "- For this question, we'll see how to use a linear regression model from Scikit-Learn\n",
    "- We'll need to use the original column 'median_house_value'. Apply the logarithmic transformation to this column.\n",
    "- Fit the Ridge regression model (model = Ridge(alpha=a, solver=\"sag\", random_state=42)) on the training data.\n",
    "- This model has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10]\n",
    "- Which of these alphas leads to the best RMSE on the validation set? Round your RMSE scores to 3 decimal digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735a5b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Function rmse and ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5d7d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse\n",
    "def rmse(y, y_pred):\n",
    "    error = y_pred - y\n",
    "    mse = (error ** 2).mean()\n",
    "    return np.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a55348b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ridge model\n",
    "def ridge(a):\n",
    "    \n",
    "    #load a old data before transformation binary in the median_house_value column\n",
    "    df= df_reg\n",
    "    \n",
    "    from sklearn.model_selection import train_test_split\n",
    "    df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "    \n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    df_val = df_val.reset_index(drop=True)\n",
    "    df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "    y_train = np.log1p(df_train['median_house_value'].values)\n",
    "    y_val = np.log1p(df_val['median_house_value'].values)\n",
    "    y_test = np.log1p(df_test['median_house_value'].values)\n",
    "\n",
    "    del df_train['median_house_value']\n",
    "    del df_val['median_house_value']\n",
    "    del df_test['median_house_value']\n",
    "    \n",
    "    df_train['ocean_proximity'] = ohe.fit_transform(df_train[categorical].values)\n",
    "    from sklearn.linear_model import Ridge\n",
    "    model = Ridge(alpha=a, solver=\"sag\", random_state=42)\n",
    "    model.fit(df_train, y_train)\n",
    "    \n",
    "    #one hot encoding for validation dataset\n",
    "    df_val['ocean_proximity'] = ohe.fit_transform(df_val[categorical].values)\n",
    "    y_pred = model.predict(df_val)\n",
    "    \n",
    "    #Round the RMSE scores to 3 decimal digits.\n",
    "    rmse_score = round(rmse(y_val, y_pred),3)\n",
    "    \n",
    "    return rmse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8df63b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha with   0 : 0.524\n",
      "alpha with 0.01 : 0.524\n",
      "alpha with 0.1 : 0.524\n",
      "alpha with   1 : 0.524\n",
      "alpha with  10 : 0.524\n"
     ]
    }
   ],
   "source": [
    "for r in [0, 0.01, 0.1, 1, 10]:\n",
    "    print('alpha with %3s' %r, ':', ridge(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7182fe",
   "metadata": {},
   "source": [
    "Based on the result, you can see with particular alpha, rmse score is similar. That's why, we will choose the smallest alpha is 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
